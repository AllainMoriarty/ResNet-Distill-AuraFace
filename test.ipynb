{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006f2fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import onnxruntime as ort\n",
    "import mxnet as mx\n",
    "from mxnet import recordio\n",
    "from umap.umap_ import UMAP\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import mlflow\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "import faiss\n",
    "import h5py\n",
    "from sklearn.metrics import roc_curve, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3546b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MXFaceDataset(Dataset):\n",
    "    def __init__(self, rec_path, idx_path, transform=None):\n",
    "        self.rec_path = rec_path\n",
    "        self.idx_path = idx_path\n",
    "        self.transform = transform\n",
    "        self.record = recordio.MXIndexedRecordIO(self.idx_path, self.rec_path, 'r')\n",
    "        self.keys = list(self.record.keys)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keys)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            key = self.keys[idx]\n",
    "            header, img = recordio.unpack(self.record.read_idx(key))\n",
    "            label = int(header.label)\n",
    "            img = mx.image.imdecode(img)\n",
    "            img = Image.fromarray(img.asnumpy())\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            return img, label\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image at index {idx}: {e}\")\n",
    "            blank_img = Image.fromarray(np.zeros((112, 112, 3), dtype=np.uint8))\n",
    "            if self.transform:\n",
    "                blank_img = self.transform(blank_img)\n",
    "            return blank_img, -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d6a6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((112, 112)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61cc102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_onnx_model(model_path):\n",
    "    so = ort.SessionOptions()\n",
    "    so.log_severity_level = 3\n",
    "    ort_session = ort.InferenceSession(\n",
    "        model_path,\n",
    "        providers=['CUDAExecutionProvider', 'CPUExecutionProvider'],\n",
    "        sess_options=so\n",
    "    )\n",
    "    return ort_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "661994a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_normalize(x):\n",
    "    norms = np.linalg.norm(x, axis=1, keepdims=True)\n",
    "    return x / np.clip(norms, 1e-10, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9c739e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(ort_session, dataloader, device='cuda', h5_path=\"embeddings.h5\", max_classes=None, sample_per_class=None):\n",
    "    if max_classes or sample_per_class:\n",
    "        print(\"[INFO] Applying class/sample subsampling before embedding generation...\")\n",
    "        label_to_indices = defaultdict(list)\n",
    "        for idx in range(len(dataloader.dataset)):\n",
    "            try:\n",
    "                _, lbl = dataloader.dataset[idx]\n",
    "                if lbl != -1:\n",
    "                    label_to_indices[lbl].append(idx)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        all_labels = list(label_to_indices.keys())\n",
    "        if max_classes and len(all_labels) > max_classes:\n",
    "            sampled_labels = np.random.choice(all_labels, max_classes, replace=False)\n",
    "        else:\n",
    "            sampled_labels = all_labels\n",
    "\n",
    "        subset_indices = []\n",
    "        for lbl in sampled_labels:\n",
    "            idxs = label_to_indices[lbl]\n",
    "            if sample_per_class and len(idxs) > sample_per_class:\n",
    "                idxs = np.random.choice(idxs, sample_per_class, replace=False).tolist()\n",
    "            subset_indices.extend(idxs)\n",
    "\n",
    "        # buat dataloader baru dengan subset\n",
    "        subset = torch.utils.data.Subset(dataloader.dataset, subset_indices)\n",
    "        dataloader = DataLoader(\n",
    "            subset,\n",
    "            batch_size=dataloader.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=dataloader.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        print(f\"[INFO] Subsampled dataset: {len(sampled_labels)} classes, {len(subset_indices)} samples\")\n",
    "\n",
    "    labels = []\n",
    "    total_samples = len(dataloader.dataset)\n",
    "\n",
    "    first_batch = True\n",
    "    offset = 0\n",
    "\n",
    "    with h5py.File(h5_path, \"w\") as h5f:\n",
    "        dset = None\n",
    "\n",
    "        pbar = tqdm(dataloader, desc=\"Generating embeddings\", unit=\"batch\")\n",
    "        with torch.inference_mode():\n",
    "            for batch_idx, (images, batch_labels) in enumerate(pbar):\n",
    "                try:\n",
    "                    images = images.to(device, non_blocking=True)\n",
    "                    resized = F.interpolate(images, size=(112, 112),\n",
    "                                            mode='bilinear', align_corners=False)\n",
    "\n",
    "                    ort_inputs = {ort_session.get_inputs()[0].name: resized.cpu().numpy()}\n",
    "                    ort_outs = ort_session.run(None, ort_inputs)\n",
    "                    emb = ort_outs[0].astype(np.float32)  # (B, D)\n",
    "\n",
    "                    # normalisasi embedding langsung\n",
    "                    emb = l2_normalize(emb)\n",
    "\n",
    "                    if first_batch:\n",
    "                        emb_dim = emb.shape[1]\n",
    "                        dset = h5f.create_dataset(\n",
    "                            \"embeddings\", (total_samples, emb_dim), dtype=\"float32\"\n",
    "                        )\n",
    "                        first_batch = False\n",
    "\n",
    "                    batch_size = emb.shape[0]\n",
    "                    dset[offset:offset+batch_size] = emb\n",
    "                    offset += batch_size\n",
    "\n",
    "                    labels.append(batch_labels.numpy())\n",
    "\n",
    "                    if batch_idx % 50 == 0:\n",
    "                        torch.cuda.empty_cache()\n",
    "                        gc.collect()\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing batch {batch_idx}: {e}\")\n",
    "                    continue\n",
    "\n",
    "    labels = np.concatenate(labels)\n",
    "    valid_mask = labels != -1\n",
    "    return h5_path, labels[valid_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7d2774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_intra_inter(h5_path, labels):\n",
    "    intra, inter = [], []\n",
    "\n",
    "    with h5py.File(h5_path, \"r\") as h5f:\n",
    "        embeddings = h5f[\"embeddings\"]\n",
    "        label_to_idx = defaultdict(list)\n",
    "        for idx, lbl in enumerate(labels):\n",
    "            label_to_idx[lbl].append(idx)\n",
    "\n",
    "        all_labels = list(label_to_idx.keys())\n",
    "\n",
    "        for lbl in all_labels:\n",
    "            idxs = label_to_idx[lbl]\n",
    "            if len(idxs) < 2:\n",
    "                continue\n",
    "            embs = np.array([embeddings[i] for i in idxs], dtype=np.float32)\n",
    "\n",
    "            index = faiss.IndexFlatIP(embs.shape[1])\n",
    "            index.add(embs)\n",
    "            D, _ = index.search(embs, embs.shape[0])\n",
    "            for i in range(embs.shape[0]):\n",
    "                intra.extend(D[i, i+1:])\n",
    "\n",
    "        all_lbls = list(label_to_idx.keys())\n",
    "        for i in range(len(all_lbls)):\n",
    "            lbl_i = all_lbls[i]\n",
    "            embs_i = np.array([embeddings[k] for k in label_to_idx[lbl_i]], dtype=np.float32)\n",
    "            for j in range(i+1, len(all_lbls)):\n",
    "                lbl_j = all_lbls[j]\n",
    "                embs_j = np.array([embeddings[k] for k in label_to_idx[lbl_j]], dtype=np.float32)\n",
    "\n",
    "                index_j = faiss.IndexFlatIP(embs_j.shape[1])\n",
    "                index_j.add(embs_j)\n",
    "                D, _ = index_j.search(embs_i, embs_j.shape[0])\n",
    "                inter.extend(D.flatten())\n",
    "\n",
    "    return np.array(intra, dtype=np.float32), np.array(inter, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97df6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_roc_auc(intra, inter):\n",
    "    y_true = np.concatenate([np.ones_like(intra), np.zeros_like(inter)])\n",
    "    y_scores = np.concatenate([intra, inter])\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_scores)\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "\n",
    "    # EER\n",
    "    fnr = 1 - tpr\n",
    "    eer_threshold = thresholds[np.nanargmin(np.absolute(fnr - fpr))]\n",
    "    eer = fpr[np.nanargmin(np.absolute(fnr - fpr))]\n",
    "\n",
    "    # Auto threshold (Youden’s J statistic)\n",
    "    j_scores = tpr - fpr\n",
    "    best_idx = np.argmax(j_scores)\n",
    "    best_threshold = thresholds[best_idx]\n",
    "\n",
    "    return fpr, tpr, auc, eer, eer_threshold, best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39b1ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_identification(h5_path, labels, k=5, max_samples=10000):\n",
    "    with h5py.File(h5_path, \"r\") as h5f:\n",
    "        embeddings_ds = h5f[\"embeddings\"]\n",
    "        N = len(labels)\n",
    "        \n",
    "        if N > max_samples:\n",
    "            idx_sample = np.random.choice(N, max_samples, replace=False)\n",
    "            embs = np.array([embeddings_ds[i] for i in idx_sample], dtype=np.float32)\n",
    "            lbls = np.array(labels)[idx_sample]\n",
    "        else:\n",
    "            embs = np.array(embeddings_ds, dtype=np.float32)\n",
    "            lbls = np.array(labels)\n",
    "        \n",
    "        dim = embs.shape[1]\n",
    "        index = faiss.IndexFlatIP(dim)\n",
    "        index.add(embs)\n",
    "\n",
    "        D, I = index.search(embs, k+1)\n",
    "        top1, topk = 0, 0\n",
    "        for i in range(embs.shape[0]):\n",
    "            neighbors = I[i][1:]\n",
    "            neighbor_labels = lbls[neighbors]\n",
    "            if neighbor_labels[0] == lbls[i]:\n",
    "                top1 += 1\n",
    "            if lbls[i] in neighbor_labels:\n",
    "                topk += 1\n",
    "\n",
    "        return top1 / embs.shape[0], topk / embs.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42d015a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_verification(intra, inter, thresholds=[0.3,0.4,0.5,0.6,0.7]):\n",
    "    results = []\n",
    "    for threshold in thresholds:\n",
    "        tp = sum(1 for sim in intra if sim >= threshold)\n",
    "        tn = sum(1 for sim in inter if sim < threshold)\n",
    "        fp = sum(1 for sim in inter if sim >= threshold)\n",
    "        fn = sum(1 for sim in intra if sim < threshold)\n",
    "        \n",
    "        accuracy = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64f77cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_similarity_distribution(intra, inter, title=\"Similarity Distribution\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.kdeplot(intra, label=\"Intra-class\", fill=True, alpha=0.5)\n",
    "    sns.kdeplot(inter, label=\"Inter-class\", fill=True, alpha=0.5)\n",
    "    plt.xlabel(\"Cosine Similarity\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab21d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(fpr, tpr, auc, title=\"ROC Curve\"):\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.4f}\")\n",
    "    plt.plot([0,1], [0,1], 'k--')\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "882cb567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_cluster(h5_path, max_samples=5000, n_neighbors=15, min_dist=0.1, n_components=2, n_clusters=10):\n",
    "    with h5py.File(h5_path, \"r\") as h5f:\n",
    "        embeddings_ds = h5f[\"embeddings\"]\n",
    "        N = len(embeddings_ds)\n",
    "        if N > max_samples:\n",
    "            idx_sample = np.random.choice(N, max_samples, replace=False)\n",
    "            embs = np.array([embeddings_ds[i] for i in idx_sample], dtype=np.float32)\n",
    "        else:\n",
    "            embs = np.array(embeddings_ds, dtype=np.float32)\n",
    "\n",
    "        # UMAP untuk reduksi dimensi\n",
    "        reducer = UMAP(n_neighbors=n_neighbors, min_dist=min_dist, \n",
    "                       n_components=n_components, random_state=42)\n",
    "        embedding_2d = reducer.fit_transform(embs)\n",
    "\n",
    "        # Clustering KMeans\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_ids = kmeans.fit_predict(embs)\n",
    "\n",
    "        # Plot hasil cluster\n",
    "        plt.figure(figsize=(10,8))\n",
    "        scatter = plt.scatter(embedding_2d[:,0], embedding_2d[:,1], \n",
    "                              c=cluster_ids, cmap=\"tab20\", s=5, alpha=0.7)\n",
    "        plt.colorbar(scatter, label=\"Cluster IDs\")\n",
    "        plt.title(f\"UMAP Projection with {n_clusters} Clusters (KMeans)\")\n",
    "        return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f9190bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = './student_resnet18.onnx'\n",
    "rec_path = './ms1m-retinaface-t1-compact/train.rec'\n",
    "idx_path = './ms1m-retinaface-t1-compact/train.idx'\n",
    "\n",
    "ort_session = load_onnx_model(model_path)\n",
    "dataset = MXFaceDataset(rec_path=rec_path, idx_path=idx_path, transform=test_transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd6996c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active provider: ['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
      "GPU\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Active provider:\", ort_session.get_providers())\n",
    "print(ort.get_device()) \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717e0a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "num_classes = len(set(all_labels))\n",
    "print(f\"Total classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8374ecf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLflow Run ID: 67c48595c4ea44d4aca1709f6066999c\n",
      "[INFO] Applying class/sample subsampling before embedding generation...\n",
      "[INFO] Subsampled dataset: 500 classes, 13754 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|██████████| 215/215 [00:07<00:00, 28.31batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to HDF5\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Face Recognition Embedding Analysis\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"Student - ResNet18 Backbone\") as run:\n",
    "    print(f\"MLflow Run ID: {run.info.run_id}\")\n",
    "\n",
    "    embeddings_path, labels = get_embeddings(ort_session, loader, max_classes=500, sample_per_class=30)\n",
    "    print(f\"Embeddings saved to HDF5\")\n",
    "\n",
    "    mlflow.log_metric(\"total_samples\", len(labels))\n",
    "    mlflow.log_metric(\"embedding_dimension\", 512)\n",
    "\n",
    "    intra, inter = compute_intra_inter(embeddings_path, labels)\n",
    "    mlflow.log_metric(\"intra_mean\", float(np.mean(intra)))\n",
    "    mlflow.log_metric(\"inter_mean\", float(np.mean(inter)))\n",
    "    mlflow.log_metric(\"separation_margin\", float(np.mean(intra) - np.mean(inter)))\n",
    "\n",
    "    top1, top5 = evaluate_identification(embeddings_path, labels, k=5)\n",
    "    mlflow.log_metric(\"top1_accuracy\", top1)\n",
    "    mlflow.log_metric(\"top5_accuracy\", top5)\n",
    "\n",
    "    verification_results = evaluate_verification(intra, inter)\n",
    "    for r in verification_results:\n",
    "        mlflow.log_metric(f\"acc_t{r['threshold']}\", r['accuracy'])\n",
    "        mlflow.log_metric(f\"prec_t{r['threshold']}\", r['precision'])\n",
    "        mlflow.log_metric(f\"rec_t{r['threshold']}\", r['recall'])\n",
    "        mlflow.log_metric(f\"f1_t{r['threshold']}\", r['f1'])\n",
    "\n",
    "    fpr, tpr, auc, eer, eer_thr, best_thr = evaluate_roc_auc(intra, inter)\n",
    "    mlflow.log_metric(\"roc_auc\", auc)\n",
    "    mlflow.log_metric(\"eer\", eer)\n",
    "    mlflow.log_metric(\"eer_threshold\", eer_thr)\n",
    "    mlflow.log_metric(\"best_threshold\", best_thr)\n",
    "\n",
    "    fig_roc = plot_roc(fpr, tpr, auc)\n",
    "    fig_roc.savefig(\"roc_curve.png\", dpi=300, bbox_inches='tight')\n",
    "    mlflow.log_artifact(\"roc_curve.png\")\n",
    "    plt.close(fig_roc)\n",
    "\n",
    "    fig_sim = plot_similarity_distribution(intra, inter)\n",
    "    fig_sim.savefig(\"similarity_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    mlflow.log_artifact(\"similarity_distribution.png\")\n",
    "    plt.close(fig_sim)\n",
    "\n",
    "    fig_umap = plot_embedding_cluster(embeddings_path, labels)\n",
    "    fig_umap.savefig(\"umap_projection.png\", dpi=300, bbox_inches='tight')\n",
    "    mlflow.log_artifact(\"umap_projection.png\")\n",
    "    plt.close(fig_umap)\n",
    "\n",
    "    mlflow.log_artifact(model_path, \"model\")\n",
    "    print(f\"✅ Full evaluation completed. AUC={auc:.4f}, EER={eer:.4f}, results saved to MLflow!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
